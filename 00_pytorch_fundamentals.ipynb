{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00. PyTorch fundamentals\n",
    "\n",
    "Resource notebook:\n",
    "    https://www.learnpytorch.io/00_pytorch_fundamentals/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to integrate your GPU with PyTorch and check if all is setup correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pytorch library\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many GPUs are available\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check index of selected GPU\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA GeForce RTX 3080', major=8, minor=6, total_memory=10239MB, multi_processor_count=68)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check index of selected GPU\n",
    "torch.cuda.get_device_properties('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3080'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a name of GPU to check if it's right\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select GPU device if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tensor is on:  cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with random values \n",
    "sample_tensor = torch.rand(0, 10)\n",
    "print('Sample tensor is on: ', sample_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tensor is on:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Moving tensor to the GPU\n",
    "sample_tensor = sample_tensor.to(device)\n",
    "print('Sample tensor is on: ', sample_tensor.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing most used libraries for data science and machine learning \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd                                                                                                                                    \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### About tensors\n",
    "\n",
    "Documentation: https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "Additional resources for understanding tensors:\n",
    "\n",
    "[1] https://towardsdatascience.com/better-visualizing-tensors-thanks-to-cities-b97e6b4ca2ca\n",
    "\n",
    "[2] https://www.youtube.com/watch?v=f5liqUk0ZTw\n",
    "\n",
    "[3] https://www.youtube.com/watch?v=bpG3gqDM80w\n",
    "\n",
    "[4] https://www.youtube.com/watch?v=YxXyN2ifK8A (best one in my opinion)\n",
    "\n",
    "Tensors are basically just a way to represent the data, and a tensor representation as matrixes and n-dim arrays is convenient way to do it. For example, if there's a tensor without any dimensions (ndim == 0) it means that's just a value a.k.a. \"scalar\". We can call it a \"rank zero\" tensor. Remember that matrixes are not tensors - it's just a way to represent them. In PyTorch it looks something like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Creating a scalar\n",
    "scalar = torch.tensor(5)\n",
    "\n",
    "# Checking if the scalar has been created correctly.\n",
    "print(scalar)\n",
    "\n",
    "# Checking scalar's number of dimensions (should be equal to 0)\n",
    "print(scalar.ndim)\n",
    "\n",
    "# Getting tensor's value as a python int (only doable with scalars)\n",
    "print(scalar.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we need more than one value to determine one object, like a vector, that contains x,y,z coordinates, we need to use a list. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 4, 6])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Creating a vector\n",
    "vector = torch.tensor([4, 4, 6])\n",
    "\n",
    "# Checking if the vector has been created correctly.\n",
    "print(vector)\n",
    "\n",
    "# Checking vector's number of dimensions.\n",
    "print(vector.ndim)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the dimension now equals to one. That's because we have one square bracket list at value initialization. But one dimensional vector isn't really useful.\n",
    "In real case scenario, we would have a list of vectors. And a list of vectors is really a matrix.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 4, 7],\n",
      "        [5, 5, 8],\n",
      "        [6, 6, 9],\n",
      "        [7, 7, 3]])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Creating a MATRIX\n",
    "MATRIX = torch.tensor([[4, 4, 7],\n",
    "                        [5, 5, 8],\n",
    "                        [6, 6, 9],\n",
    "                        [7, 7, 3]])\n",
    "\n",
    "# Checking if the MATRIX has been created correctly.\n",
    "print(MATRIX)\n",
    "\n",
    "# Checking vector's number of dimensions. \n",
    "print(MATRIX.ndim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we have a complicated structure that requires list of matrixes, it really means that we need store data in a 3-dimensional tensor. Real life example would be an image that has three channels: red, green, and blue. Each of the channels is a matrix that shows the intensity of each pixel in that channel. To describe the structure of the single image, we need each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [5, 6, 7],\n",
      "         [7, 8, 9]]])\n",
      "3\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Creating a 3D vector (rank 1 tensor in 3 dimensions)\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [5, 6, 7],\n",
    "                        [7, 8, 9]]])\n",
    "\n",
    "# Checking if the vector has been created correctly. \n",
    "print(TENSOR)\n",
    "\n",
    "# Checking vector's number of dimensions \n",
    "print(TENSOR.ndim)\n",
    "\n",
    "# Checking a size of a tensor \n",
    "print(TENSOR.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So tensors are really an organized data structure, and they have as many rows and columns as there are needed to describe one object or a whole model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random tensors\n",
    "\n",
    "The way that machine learning models are trained is by using random tensors. It is because they start with tensors full of random numbers and then they adjust their values to better fit the data.\n",
    "\n",
    "`Start with a random tensor -> look at the data -> adjust the values to better fit the data -> repeat the step 2 and 3 until you get right values`\n",
    "\n",
    "Torch random tensors: https://pytorch.org/docs/stable/generated/torch.rand.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2821, 0.4957, 0.4892, 0.8279],\n",
      "        [0.0867, 0.8728, 0.8622, 0.7512],\n",
      "        [0.1039, 0.8838, 0.7903, 0.7171]])\n",
      "torch.Size([3, 4])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Create random tensor \n",
    "random_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Show random tensor\n",
    "print(random_tensor)\n",
    "\n",
    "# Show random tensor shape\n",
    "print(random_tensor.shape)\n",
    "\n",
    "# Show random tensor ndim\n",
    "print(random_tensor.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([224, 224, 3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Create a random tensor that is similar to an image tensor.\n",
    "random_image_tensor = torch.rand(size=(224, 224, 3)) # height, width, color channels (R, G, B)\n",
    "print(random_image_tensor.shape)\n",
    "print(random_image_tensor.ndim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor of all zeros\n",
    "zeros = torch.zeros(3, 4)\n",
    "print(zeros)\n",
    "print(zeros * random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create tensor of all ones \n",
    "ones = torch.ones(3, 4)\n",
    "print(ones)\n",
    "print(ones.dtype) #default type for pytorch is torch.float32\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# Use torch.arange()\n",
    "one_to_ten = torch.arange(0, 10) # torch.arange(start=0, end=11, step=2)\n",
    "print(one_to_ten)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a tensor and we want to create another tensor that is the same shape as the original one, but filled with zeros/one, we can use zeros_like/ones/like method, like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Creating tensor-like \n",
    "ten_zeros = torch.zeros_like(one_to_ten) # torch.ones_like(one_to_ten)\n",
    "print(ten_zeros)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor datatypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision in computing: https://en.wikipedia.org/wiki/Precision_(computer_science)\n",
    "\n",
    "**Note:** Wrong tensor datatype is one of three most common errors anyone can run into with PyTorch and Deep Learning. All most common errors are listed below:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on right device\n",
    "\n",
    "PyTorch's default datatype is torch.float32 as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 7., 5.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "f32_tensor = torch.tensor([3.0, 7.0, 5.0],\n",
    "                           dtype=None, # What datatype is the tensor. All listed on https://pytorch.org/docs/stable/tensors.html\n",
    "                           device=None, # What device is your tensor on. By default the device is 'cpu'.\n",
    "                           requires_grad=False) # Whether or not to track the gradient of the tensor wih its operations.\n",
    "print(f32_tensor)\n",
    "print(f32_tensor.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can change it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 7., 5.], dtype=torch.float64)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Float 64 tensor\n",
    "f64_tensor = torch.tensor([3.0, 7.0, 5.0],\n",
    "                           dtype=torch.float64, \n",
    "                           device=None, \n",
    "                           requires_grad=False) \n",
    "\n",
    "print(f64_tensor)\n",
    "print(f64_tensor.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch can manage to operate on tensors with different datatypes, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9., 49., 25.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(f32_tensor * f64_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But sometimes it is not so obvious."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting information from tensors\n",
    "\n",
    "1. Tensors not right datatype - to get datatype of tensors, use: `tensor.dtype`\n",
    "2. Tensors not right shape - to get shape of tensors, use: `tensor.shape`\n",
    "3. Tensors not on right device - to get device of tensors, use: `tensor.device`\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2662, 0.4129, 0.1507, 0.8818],\n",
      "        [0.9928, 0.4468, 0.2544, 0.7183],\n",
      "        [0.9988, 0.3611, 0.0520, 0.6360]])\n",
      "Datatype of the tensor: torch.float32\n",
      "Shape of the tensor: torch.Size([3, 4])\n",
      "Device on which the tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Crete a tensor\n",
    "TENSOR = torch.rand(3, 4)\n",
    "\n",
    "# Show the tensor\n",
    "print(TENSOR)\n",
    "\n",
    "# Get a datatype of the tensor\n",
    "print(f'Datatype of the tensor: {TENSOR.dtype}')\n",
    "\n",
    "# Get the shape of the tensor\n",
    "print(f'Shape of the tensor: {TENSOR.shape}') # Can use .size() to get the size of the tensor. One is a method and one is a attribute.\n",
    "\n",
    "# Get the device of the tensor\n",
    "print(f'Device on which the tensor is on: {TENSOR.device}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulating tensors - tensor operations\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise multiplication)\n",
    "* Division\n",
    "* Matrix multiplication\n",
    "\n",
    "There are two main rules that performing matrix multiplication needs to satisfy:\n",
    "\n",
    "1. The **inner dimensions** of the two tensors must match:\n",
    "   * `(3, 2) @ (3, 2)` -> won't work\n",
    "   * `(2, 3) @ (3, 2)` -> will work\n",
    "   * `(3, 2) @ (2, 3)` -> will work\n",
    "2. The resulting matrix has the shape of the **outer dimensions**:\n",
    "   * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    "   * `(3, 2) @ (2, 3)` -> `(3, 3)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n",
      "tensor([11, 12, 13])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" How to add a value to a tensor \"\"\"\n",
    "# Create a tensor \n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Addition\n",
    "print(tensor + 10)\n",
    "\n",
    "# Alternatively we can use torch.add()\n",
    "print(torch.add(tensor, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9, -8, -7])\n",
      "tensor([-9, -8, -7])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" How to subtract a value from a tensor \"\"\"\n",
    "# Create a tensor \n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Subtraction\n",
    "print(tensor - 10)\n",
    "\n",
    "# Alternatively we can use torch.sub()\n",
    "print(torch.sub(tensor, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 20, 30])\n",
      "tensor([10, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" How to multiply a tensor by a scalar \"\"\"\n",
    "# Create a tensor \n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Multiplication\n",
    "print(tensor * 10)\n",
    "\n",
    "# Alternatively we can use torch.mul()\n",
    "print(torch.mul(tensor, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000, 0.2000, 0.3000])\n",
      "tensor([0.1000, 0.2000, 0.3000])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" How to divide a tensor by a scalar \"\"\"\n",
    "# Create a tensor \n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Multiplication\n",
    "print(tensor / 10)\n",
    "\n",
    "# Alternatively we can use torch.div()\n",
    "print(torch.div(tensor, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix multiplication\n",
    "\n",
    "Two ways of performing multiplication in ML&DL:\n",
    "\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "More on Matrix multiplication: https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals to: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor \n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Element wise multiplication\n",
    "print(f'{tensor} * {tensor}\\nEquals to: {tensor * tensor}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication can be done by hand or by using torch.matmul() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By hand:  tensor(14)\n",
      "Matmul function:  tensor(14)\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication by hand\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print('By hand: ', value)\n",
    "\n",
    "# Matrix multiplication with torch.matmul() function\n",
    "print('Matmul function: ', torch.matmul(tensor, tensor))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we need to bare in mind that PyTorch has been created to be efficient in its calculation. Therefore using torch.matmal() function is ten times faster than using loops."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most common error in Deep Learning: shape error\n",
    "\n",
    "Previous example was rather simple, therefore we didn't get any error. \n",
    "\n",
    "Let's break the first rule of matrix multiplication -\n",
    "\n",
    "\"1. The **inner dimensions** of the two tensors must match:\n",
    "   * `(3, 2) @ (3, 2)` -> won't work\n",
    "   * `(2, 3) @ (3, 2)` -> will work\n",
    "   * `(3, 2) @ (2, 3)` -> will work\"\n",
    "\n",
    ", and find out what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23936\\2029646469.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "torch.matmul(torch.rand(3, 2), torch.rand(3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21108\\2089530497.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                          [11, 12]])\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_B\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# torch.mm is an alias for torch.matmul\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7, 8],\n",
    "                         [9, 10],\n",
    "                         [11, 12]])\n",
    "\n",
    "print(torch.mm(tensor_A, tensor_B)) # torch.mm is an alias for torch.matmul\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this issue, we can multiply the shape of one of our tensors using **transpose**.\n",
    "\n",
    "**Transpose** - an operation that switches axes or dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n",
      "tensor([[ 7,  9, 11],\n",
      "        [ 8, 10, 12]])\n",
      "tensor([[ 23,  29,  35],\n",
      "        [ 53,  67,  81],\n",
      "        [ 83, 105, 127]])\n"
     ]
    }
   ],
   "source": [
    "# Original tensor\n",
    "print(tensor_B)\n",
    "\n",
    "# Transposed tensor\n",
    "print(tensor_B.T)\n",
    "\n",
    "# Multiplication\n",
    "print(torch.mm(tensor_A, tensor_B.T))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's step by step what happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. We get original tensors\n",
      " - Original shape of tensor_A: torch.Size([3, 2])\n",
      " - Original shape of tensor_B: torch.Size([3, 2])\n",
      "2. We transpose the tensor_A or tensor_B. It's your choice.\n",
      " - New shape of new transposed tensor_B: torch.Size([2, 3])\n",
      "3. As the inner dimensions of tensor_A and tensor_B are the same, we can multiply them together.\n",
      "Output: tensor([[ 23,  29,  35],\n",
      "        [ 53,  67,  81],\n",
      "        [ 83, 105, 127]])\n",
      "4. The result matrix has the same dimensions as outer dimensions of tensor_A and tensor_B, which are 3 and 3\n",
      " - Shape of result matrix: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print('1. We get original tensors')\n",
    "print(f' - Original shape of tensor_A: {tensor_A.shape}')\n",
    "print(f' - Original shape of tensor_B: {tensor_B.shape}')\n",
    "print(\"2. We transpose the tensor_A or tensor_B. It's your choice.\")\n",
    "print(f' - New shape of new transposed tensor_B: {tensor_B.T.shape}')\n",
    "print('3. As the inner dimensions of tensor_A and tensor_B are the same, we can multiply them together.')\n",
    "output = torch.mm(tensor_A, tensor_B.T)\n",
    "print(f'Output: {output}')\n",
    "print(f'4. The result matrix has the same dimensions as outer dimensions of tensor_A and tensor_B, which are 3 and 3')\n",
    "print(f' - Shape of result matrix: {output.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of the second rule of matrix multiplication\n",
    "\n",
    "\"2. The resulting matrix has the shape of the **outer dimensions**:\n",
    "   * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    "   * `(3, 2) @ (2, 3)` -> `(3, 3)`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5236, 0.2829, 0.5608],\n",
      "        [0.3272, 0.5757, 0.3321],\n",
      "        [0.2349, 0.1500, 0.2505]])\n",
      "tensor([[0.9166, 0.9019],\n",
      "        [0.9706, 0.9475]])\n",
      "tensor([[3.7839, 2.6333, 3.7173],\n",
      "        [2.2040, 1.8659, 2.5815],\n",
      "        [3.3008, 2.1486, 3.6346]])\n",
      "tensor([[3.5925, 3.3448, 3.3426, 3.2264, 2.5871],\n",
      "        [3.1340, 3.6557, 2.9148, 3.5357, 2.3806],\n",
      "        [2.6682, 2.5946, 2.6844, 2.3902, 1.8340]])\n"
     ]
    }
   ],
   "source": [
    "# (3, 2) @ (2, 3) -> (3, 3)\n",
    "print(torch.matmul(torch.rand(3,2), torch.rand(2,3)))\n",
    "\n",
    "# (2, 3) @ (3, 2) -> (2, 2)\n",
    "print(torch.matmul(torch.rand(2,3), torch.rand(3,2)))\n",
    "\n",
    "# (3, 10) @ (10, 3) -> (3, 3)\n",
    "print(torch.matmul(torch.rand(3,10), torch.rand(10,3)))\n",
    "\n",
    "# (3, 10) @ (10, 5) -> (3, 5)\n",
    "print(torch.matmul(torch.rand(3,10), torch.rand(10,5)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the min, max, mean, sum etc. (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "tensor(0)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Finding minimal value in the tensor \"\"\"\n",
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "\n",
    "# Show the tensor\n",
    "print(x)\n",
    "\n",
    "# Find the minimal value in tensor\n",
    "print(torch.min(x))\n",
    "\n",
    "# Alternative way to find minimum value in tensor\n",
    "print(x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "tensor(90)\n",
      "tensor(90)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Finding maximum value in the tensor \"\"\"\n",
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "\n",
    "# Show the tensor\n",
    "print(x)\n",
    "\n",
    "# Find maximum value in tensor\n",
    "print(torch.max(x))\n",
    "\n",
    "# Alternative way to find maximum value in tensor\n",
    "print(x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0., 10., 20., 30., 40., 50., 60., 70., 80., 90.])\n",
      "tensor(45.)\n",
      "tensor(45.)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Finding average value in the tensor \"\"\"\n",
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10, dtype=torch.float32)\n",
    "\n",
    "# Show the tensor\n",
    "print(x)\n",
    "\n",
    "# Find mean value in tensor - note: torch.mean() function requires a torch.float32 dtype\n",
    "print(torch.mean(x))\n",
    "\n",
    "# Alternative way to find mean value in tensor\n",
    "print(x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "tensor(450)\n",
      "tensor(450)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Finding a sum of the tensor \"\"\"\n",
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "\n",
    "# Show the tensor\n",
    "print(x)\n",
    "\n",
    "# Find a sum of the tensor\n",
    "print(torch.sum(x))\n",
    "\n",
    "# Alternative way to find a sum of the tensor\n",
    "print(x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n",
      "tensor(0)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Finding a position (index) of min in the tensor \"\"\"\n",
    "# Create a tensor\n",
    "x = torch.arange(1, 100, 10)\n",
    "\n",
    "# Show the tensor\n",
    "print(x)\n",
    "\n",
    "# Find a position (index) of min in the tensor\n",
    "print(torch.argmin(x))\n",
    "\n",
    "# Alternative way to find a position (index) of min in the tensor\n",
    "print(x.argmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n",
      "tensor(9)\n",
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Finding a position (index) of max in the tensor \"\"\"\n",
    "# Create a tensor\n",
    "x = torch.arange(1, 100, 10)\n",
    "\n",
    "# Show the tensor\n",
    "print(x)\n",
    "\n",
    "# Find a position (index) of max in the tensor\n",
    "print(torch.argmax(x))\n",
    "\n",
    "# Alternative way to find a position (index) of max in the tensor\n",
    "print(x.argmax())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - return a view of the input with dimensions permuted (swapped) in certain way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]) torch.Size([9])\n",
      "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]) torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(1., 10.)\n",
    "print(x, x.shape)\n",
    "\n",
    "# Add a new dimension\n",
    "x_reshaped = x.reshape(1, 9)\n",
    "print(x_reshaped, x_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]) torch.Size([1, 9])\n",
      "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]) tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(1, 9)\n",
    "print(z, z.shape)\n",
    "\n",
    "# Changing z changes x because a view of a tensor shares the same memory as the original input\n",
    "z[:, 0] = 5\n",
    "print(z, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5., 5., 5.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [8., 8., 8., 8.],\n",
      "        [9., 9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x]) # dim = 1\n",
    "print(x_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]) torch.Size([1, 9])\n",
      "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]) torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() removes all 1 dimensions\n",
    "print(x_reshaped, x_reshaped.shape)\n",
    "print(x_reshaped.squeeze(), x_reshaped.squeeze().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "torch.Size([9])\n",
      "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() adds 1 dimensions\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(x_squeezed)\n",
    "print(x_squeezed.shape)\n",
    "x_unsqueezed = x_squeezed.unsqueeze(0)\n",
    "print(x_unsqueezed)\n",
    "print(x_unsqueezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearranges the dimensions of target tensor in a specified order\n",
    "x = torch.randn(2, 3, 5)\n",
    "print(x.shape)\n",
    "x_permuted = torch.permute(x, (2, 0, 1))\n",
    "print(x_permuted.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing\n",
    "\n",
    "Indexing in PyTorch is similar to indexing with NumPy arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]]) torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor \n",
    "import torch\n",
    "\n",
    "x = torch.arange(1,10).reshape(1, 3 ,3)\n",
    "print(x, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's index on our new tensor\n",
    "print(x[0, 0, 1]) #change '0' in square brackets and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 7]])\n"
     ]
    }
   ],
   "source": [
    "# You can use \":\" to select all of target dimension\n",
    "print(x[:, :, 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch tensors and NumPy\n",
    "\n",
    "NumPy is very popular scientific Python numerical computing library. s\n",
    "And because of it, PyTorch has functionality to interact with it.\n",
    "* Data in NumPy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7.] tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array) # When converting from numpy array to torch tensor default dtype is float64\n",
    "print(array, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2.]) [1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "print(tensor, numpy_tensor)\n",
    "tensor = tensor + 1\n",
    "print(tensor, numpy_tensor) # They don't share memory\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducibility (Creating seed)\n",
    "\n",
    "Extra resources:\n",
    "* https://pytorch.org/docs/stable/notes/randomness.html\n",
    "* https://en.wikipedia.org/wiki/Random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7206, 0.2809, 0.1826, 0.1297],\n",
      "        [0.4757, 0.5004, 0.3709, 0.4002],\n",
      "        [0.2189, 0.3464, 0.8074, 0.8887]])\n",
      "tensor([[0.1233, 0.4134, 0.1043, 0.1843],\n",
      "        [0.0656, 0.3246, 0.3044, 0.7056],\n",
      "        [0.0455, 0.3311, 0.9790, 0.9308]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "RANDOM_SEED = 2137\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting tensors (and models) on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n",
      "tensor([1, 2, 3], device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Create tensor (default on the CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "#Tensor not on GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Move tensor to GPU\n",
    "tensor_gpu = tensor.to(device)\n",
    "print(tensor_gpu, tensor_gpu.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0dfddf38355eb1c7bbdbf09c07de05c9912bc8a91970103b0afd28feba3a117"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
